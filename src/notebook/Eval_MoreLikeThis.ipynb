{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook have all the backend code needed for you to run an interface to evaluate the documents more like this is returning are relevant to your solution.\n",
    "\n",
    "The Azure Services we are using in this case:\n",
    "* Azure Search\n",
    "* Azure Storage Account\n",
    "    * Containers\n",
    "    * Tables\n",
    "\n",
    "This code can be used in the notebook, as is, you just need to set up the environment variables:\n",
    "\n",
    "```python \n",
    "os.environ['SEARCH_SVC'] = <search service name>\n",
    "os.environ['SEARCH_SUBSCRIPTION_KEY'] = <search subscription key>\n",
    "os.environ['STORAGE_ACCOUNT_NAME'] = <storage account name>\n",
    "os.environ['STORAGE_ACCOUNT_KEY'] = <storage account key>\n",
    "```\n",
    "\n",
    "Or, it can be implemented directly in a WebApp or Azure Functions, it's up to you!\n",
    "\n",
    "Basic functionality:\n",
    "\n",
    "This function will run a search in Azure Search, and retrieve 20% of all the documents that we will be used as baseline to test More Like This API.\n",
    "\n",
    "In the code below I explain it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing: the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section we will create the string that will allow us to connect to the Azure Search service and define the values we will be using through the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables defined in the following section are self-explainable, but some worth mention:\n",
    "\n",
    "* searchSvc: the search service you created in Azure;\n",
    "* headers { api-key }: the key for the search service;\n",
    "* searchFields: the field you want to use in More Like This when it searchs the other documents;\n",
    "* totalDocuments: the total number of documents in your Storage Account;\n",
    "* userName: used as PartitionKey in Azure Table.\n",
    "* rowKey: the RowKey in Azure Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchSvc = os.environ['SEARCH_SVC']\n",
    "endpoint = 'https://'+ searchSvc + '.search.windows.net/'\n",
    "apiVersion = '?api-version=2019-05-06-Preview'\n",
    "headers = {'Content-Type': 'application/json',\n",
    "           'api-key': os.environ['SEARCH_SUBSCRIPTION_KEY']}\n",
    "searchFields = 'merged_content'\n",
    "numMoreLikeThisDocs = '3'\n",
    "\n",
    "totalDocuments = 50\n",
    "numDocsToSelect = int(totalDocuments*0.2)\n",
    "userName = 'Squassina'\n",
    "\n",
    "rowKey = str(datetime.date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will retrieve the possible indexes. By default I am considering there is only one index in the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = endpoint + \"indexes\" + apiVersion + \"&$select=name\"\n",
    "response  = requests.get(url, headers=headers)\n",
    "indexList = response.json()\n",
    "indexName = indexList['value'][0]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function if to select the documents I'm using to evaluate the service. \n",
    "\n",
    "I will select a random integer (a) to elect the document I will use to test if More Like This is returning relevant documents.\n",
    "\n",
    "By using Azure Search to retrieve the first document after skipping (a), I'm selecting only a few fields to accelerate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_source_documents():\n",
    "    randDoc = random.randint(0,totalDocuments)\n",
    "    url = endpoint + 'indexes/' + indexName + '/docs' + apiVersion + '&$select=Id,metadata_storage_path&$top=1&$skip=' + str(randDoc)\n",
    "    response  = requests.get(url, headers=headers)\n",
    "    return(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will retrieve the documents returned by More Like This for me to do the evaluation. Here, two key fields worth noticing:\n",
    "* moreLikeThis; and\n",
    "* searchField\n",
    "\n",
    "According to the [documentation](https://docs.microsoft.com/en-us/azure/search/search-more-like-this): \n",
    "> ` moreLikeThis=[key] ` is a query parameter in the Search Documents API that finds documents similar to the document specified by the document key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_like_this_docs(odocId: str):\n",
    "    url = endpoint + 'indexes/' + indexName + '/docs' + apiVersion + '&$moreLikeThis='+ odocId + '&searchFields=' + searchFields + '&$top=' + numMoreLikeThisDocs\n",
    "    response  = requests.get(url, headers=headers)\n",
    "    return(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following 2 sections we start the process to select the documents and the results of More Like This to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceDocList = {}\n",
    "random.seed('More Like This')\n",
    "\n",
    "for i in range(numDocsToSelect):\n",
    "    sourceDocList[i] = (select_source_documents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt = {}\n",
    "\n",
    "for i in range(len(sourceDocList)):\n",
    "    mlt[i] = more_like_this_docs(sourceDocList[i]['value'][0]['Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I send everything to a Pandas DataFrame before storing for better visualization, because I am working with a very small set of documents, but you may skip this section and move to Store data in Azure Storage Account / Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsDf = pd.DataFrame(columns = ['RowKey','PartitionKey',\n",
    "                                  'source_id','source_stg_path',\n",
    "                                  'MLT_1_id','MLT_1_stg_path','MLT_1_score',\n",
    "                                  'MLT_2_id','MLT_2_stg_path','MLT_2_score',\n",
    "                                  'MLT_3_id','MLT_3_stg_path','MLT_3_score',\n",
    "                                  'EVAL_1', 'EVAL_2', 'EVAL_3','DCG'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you notice well, there are 4 additional fields I created above that I'm not using below: `EVAL_1, EVAL_2, EVAL_3, DCG`. These fields will be used when you are doing the evaluation in the UI: one evaluation for each document returned by MoreLikeThis and the final calculation of the relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsDf.RowKey = [rowKey + ' - ' + str(x) for x in range(len(sourceDocList))]\n",
    "docsDf.PartitionKey = [userName for x in range(len(sourceDocList))]\n",
    "docsDf.source_id = [sourceDocList[i]['value'][0]['Id'] for i in range(len(sourceDocList))]\n",
    "docsDf.source_stg_path = [sourceDocList[i]['value'][0]['metadata_storage_path'].replace('%C3%A7%C3%A3', 'çã').replace('%C3%87%C3%83','ÇÃ').replace('%C3%A9','é')\n",
    "                          for i in range(len(sourceDocList))]\n",
    "docsDf.MLT_1_id = [mlt[i]['value'][0]['Id'] for i in range(len(mlt))]\n",
    "docsDf.MLT_1_stg_path = [mlt[i]['value'][0]['metadata_storage_path'].replace('%C3%A7%C3%A3', 'çã').replace('%C3%87%C3%83','ÇÃ').replace('%C3%A9','é')\n",
    "                         for i in range(len(mlt))]\n",
    "docsDf.MLT_1_score = [mlt[i]['value'][0]['@search.score'] for i in range(len(mlt))]\n",
    "docsDf.MLT_2_id = [mlt[i]['value'][1]['Id'] for i in range(len(mlt))]\n",
    "docsDf.MLT_2_stg_path = [mlt[i]['value'][1]['metadata_storage_path'].replace('%C3%A7%C3%A3', 'çã').replace('%C3%87%C3%83','ÇÃ').replace('%C3%A9','é')\n",
    "                         for i in range(len(mlt))]\n",
    "docsDf.MLT_2_score = [mlt[i]['value'][1]['@search.score'] for i in range(len(mlt))]\n",
    "docsDf.MLT_3_id = [mlt[i]['value'][2]['Id'] for i in range(len(mlt))]\n",
    "docsDf.MLT_3_stg_path = [mlt[i]['value'][2]['metadata_storage_path'].replace('%C3%A7%C3%A3', 'çã').replace('%C3%87%C3%83','ÇÃ').replace('%C3%A9','é')\n",
    "                         for i in range(len(mlt))]\n",
    "docsDf.MLT_3_score = [mlt[i]['value'][2]['@search.score'] for i in range(len(mlt))]\n",
    "docsDf.EVAL_1 = None\n",
    "docsDf.EVAL_2 = None\n",
    "docsDf.EVAL_3 = None\n",
    "docsDf.DCG = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsDf.to_csv('./docs_to_be_evaluated.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store data in Azure Storage Account / Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't want to work in memory and loose everything I have done so far, so I store the results of above code in Azure Tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imports for this section of the code are for Azure Storage. If you need to install it, the command is: \n",
    "\n",
    "`pip install azure-storage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.storage import CloudStorageAccount\n",
    "from azure.storage.table import TableService, Entity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsDict = pd.read_csv('./docs_to_be_evaluated.csv').to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'm setting the account by reading the Storage Account Name and Key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accountName = os.environ['STORAGE_ACCOUNT_NAME']\n",
    "\n",
    "accountKey = os.environ['STORAGE_ACCOUNT_KEY']\n",
    "\n",
    "account = CloudStorageAccount(accountName, accountKey)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the table service. I am using a table called `MLTEval` to store the data from the first part of this solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableName = 'MLTEval'\n",
    "tableService = account.create_table_service()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For educational purposes only, I'm leaving the code to delete and create table here, but it's not needed after the first run as we will save this to compare after the users start using the system that the documents retrieved are still relevant, or it's needed to adjust something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tableService.delete_table(tableName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_table` wil return `true` if the table was created or `false`, if the table already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableService.create_table(tableName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'm inserting the data I collected in the first section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(docsDict)):\n",
    "    tableService.insert_or_replace_entity(tableName, docsDict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default function to retrieve data from Azure Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm saving this function outside the two sections to come as it's a common function to both.\n",
    "\n",
    "This function retrieve data from Azure Table where I stored the data prepared in the section above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data_azure_table(partitionKey : str, rowKey : str):\n",
    "    import os\n",
    "    from azure.storage import CloudStorageAccount\n",
    "    from azure.storage.table import TableService, Entity\n",
    "    import numpy as np\n",
    "\n",
    "    accountName = os.environ['STORAGE_ACCOUNT_NAME']\n",
    "    \n",
    "    accountKey = os.environ['STORAGE_ACCOUNT_KEY']\n",
    "    \n",
    "    account = CloudStorageAccount(accountName, accountKey)\n",
    "\n",
    "    filter = \"PartitionKey eq '\" + partitionKey + \"' and RowKey gt '\" + rowKey + \"'\"\n",
    "\n",
    "    tableService = account.create_table_service()\n",
    "    \n",
    "    return(tableService.query_entities(table_name = tableName, filter = filter))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Original Document with what was found and giving the documents a score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HTML, Box, HBox, VBox, Layout\n",
    "from azure.storage.table import TableService, Entity\n",
    "import azure.storage.blob\n",
    "from azure.storage import CloudStorageAccount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I kept this section here as one may want to run this section directly at a later time, without need to run the full notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accountName = os.environ['STORAGE_ACCOUNT_NAME']\n",
    "accountKey = os.environ['STORAGE_ACCOUNT_KEY']\n",
    "account = CloudStorageAccount(accountName, accountKey)\n",
    "\n",
    "userName = 'Squassina'\n",
    "rowKey = str(datetime.date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableName = 'MLTEval'\n",
    "tableService = account.create_table_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsDf = retrieve_data_azure_table(partitionKey = userName, rowKey = rowKey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll get the values to work in a dictionary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_docs = [row for row in docsDf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll define the functions to display and update the score for the documents retrieved by MoreLikeThis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm working with 20% of the documents, so I want to be able to navigate through that documents and preview both the source document and the 3 top documents retrieved by MoreLikeThis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to allow me to navigate through the source documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_SRC(i: int):\n",
    "    src_value = '<embed src=\"{}\", raw=True) width=\"100%\" height=\"400px\" />'.format(working_docs[i].source_stg_path)\n",
    "    display(widgets.HTML(value=src_value, layout=Layout(flex='1 1 auto', width='auto')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to allow me to navigate through the documents retrieved by MoreLikeThis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_MLT(i: int,j: int):\n",
    "    if j == 1:\n",
    "        mlt_value = '<embed src=\"{}\", raw=True) width=\"100%\" height=\"400px\" />'.format(working_docs[i].MLT_1_stg_path)\n",
    "    elif j == 2:\n",
    "        mlt_value = '<embed src=\"{}\", raw=True) width=\"100%\" height=\"400px\" />'.format(working_docs[i].MLT_2_stg_path)\n",
    "    elif j == 3:\n",
    "        mlt_value = '<embed src=\"{}\", raw=True) width=\"100%\" height=\"400px\" />'.format(working_docs[i].MLT_3_stg_path)\n",
    "    display(widgets.HTML(value=mlt_value, layout=Layout(flex='1 1 auto', width='auto')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to update the values in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_eval_values(b):\n",
    "    if drop_mlt_doc.value == 1:\n",
    "        working_docs[drop_src_doc.value].EVAL_1 = eval_mlt.value\n",
    "    if drop_mlt_doc.value == 2:\n",
    "        working_docs[drop_src_doc.value].EVAL_2 = eval_mlt.value\n",
    "    if drop_mlt_doc.value == 3:\n",
    "        working_docs[drop_src_doc.value].EVAL_3 = eval_mlt.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm creating the interface to the user of the notbook to evaluate MoreLikeThis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'm creating the layout to present both documents side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_layout = Layout(display='flex',\n",
    "                    flex_flow='row',\n",
    "                    align_items='stretch',\n",
    "                    border='none',\n",
    "                    width='100%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating 2 dropdowns to display the source document..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_src_doc = widgets.Dropdown(\n",
    "    description='Ori Doc',\n",
    "    options=[(working_docs[i].source_stg_path.split(sep='/')[-1].split(sep=\"']\")[0],i) for i in range(len(working_docs))],\n",
    "    value=0,\n",
    "    layout=Layout(display='flex', flex='1 1 0%', flex_flow='row', align_items='flex-start', width='15%')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the top 3 documents retrieved by MoreLikeThis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_mlt_doc = widgets.Dropdown(\n",
    "    description='MoreLikeThis',\n",
    "    options=[('MLT 1', 1), ('MLT 2', 2), ('MLT 3', 3)],\n",
    "    value=1,\n",
    "    layout=Layout(display='flex',flex='1 1 auto', flex_flow='row', align_items='center', width='auto')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I'm getting the values of the 2 dropdowns to update the document view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change source document..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_src = widgets.interactive_output(change_SRC, {'i': drop_src_doc})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and MoreLikeThis documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mlt = widgets.interactive_output(change_MLT, {'i': drop_src_doc,'j': drop_mlt_doc})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I'm creating a slider with the possible score for the MoreLikeThis results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_mlt = widgets.IntSlider(value=0, min=0, max=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a button to save the score to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mlt = widgets.Button(description=\"Save Evaluation\")\n",
    "score_mlt.on_click(submit_eval_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I'm creating the box to place all the widgets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = widgets.VBox(\n",
    "    [widgets.HBox(\n",
    "        [drop_src_doc,drop_mlt_doc]),\n",
    "     widgets.HBox([out_src, out_mlt], \n",
    "                  layout=box_layout),\n",
    "     widgets.HBox([eval_mlt,score_mlt])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I'm showing the box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I can save the dataframe to Azure Tables with the scores fulfilled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(working_docs)):\n",
    "    tableService.insert_or_replace_entity(tableName, working_docs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Discount Cumulative Gain (DCG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will calculate DCG. I didn't wrote it, the code is available in the website as indicated in the comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure.storage.table import TableService, Entity, EntityProperty, EdmType\n",
    "from azure.storage import CloudStorageAccount\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accountName = os.environ['STORAGE_ACCOUNT_NAME']\n",
    "accountKey = os.environ['STORAGE_ACCOUNT_KEY']\n",
    "account = CloudStorageAccount(accountName, accountKey)\n",
    "\n",
    "userName = 'Squassina'\n",
    "rowKey = str(datetime.date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableName = 'MLTEval'\n",
    "tableService = account.create_table_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k, method=0):\n",
    "    import numpy as np\n",
    "    # https://gist.github.com/bwhite/3726239\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> dcg_at_k(r, 1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 1, method=1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 2)\n",
    "    5.0\n",
    "    >>> dcg_at_k(r, 2, method=1)\n",
    "    4.2618595071429155\n",
    "    >>> dcg_at_k(r, 10)\n",
    "    9.6051177391888114\n",
    "    >>> dcg_at_k(r, 11)\n",
    "    9.6051177391888114\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Discounted cumulative gain\n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will take partitionKey and rowKey as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data_azure_table(partitionKey : str, rowKey : str):\n",
    "    import os\n",
    "    from azure.storage import CloudStorageAccount\n",
    "    from azure.storage.table import TableService, Entity\n",
    "    import numpy as np\n",
    "\n",
    "    accountName = os.environ['STORAGE_ACCOUNT_NAME']\n",
    "    \n",
    "    accountKey = os.environ['STORAGE_ACCOUNT_KEY']\n",
    "    \n",
    "    account = CloudStorageAccount(accountName, accountKey)\n",
    "\n",
    "    filter = \"PartitionKey eq '\" + partitionKey + \"' and RowKey gt '\" + rowKey + \"'\"\n",
    "\n",
    "    tableService = account.create_table_service()\n",
    "    \n",
    "    return(tableService.query_entities(table_name = tableName, filter = filter))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using the userName as partitionKey in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsDf = retrieve_data_azure_table(partitionKey = userName, rowKey = rowKey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running DCG in the data as is will return NaN if we don't have any evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "DCG = []\n",
    "for row in docsDf:            \n",
    "    dcg = dcg_at_k( [row['EVAL_1'], row['EVAL_2'], row['EVAL_3']], k, 1 )\n",
    "    row.DCG = EntityProperty(EdmType.DOUBLE, dcg)\n",
    "    DCG.append(dcg)\n",
    "    \n",
    "#DCG = pd.DataFrame( data = {'DCG':DCG} )\n",
    "\n",
    "print(DCG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that there is a trick to store the DCG in the table. Here : `row.DCG = EntityProperty(EdmType.DOUBLE, dcg)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to print the values, the result would be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in docsDf:\n",
    "    print(row['DCG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the actual values, you will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in docsDf:\n",
    "    print(row['DCG'].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save everything to Azure Tables. Don't worry, the values are stored correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in docsDf.items:\n",
    "    tableService.insert_or_replace_entity(tableName, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
